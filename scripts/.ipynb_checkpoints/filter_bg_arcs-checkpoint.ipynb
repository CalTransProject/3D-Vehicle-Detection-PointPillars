{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e7e623-3db1-47b0-a2a9-dd076b04be2b",
   "metadata": {},
   "source": [
    "# Filter each stationary frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "7a689bb4-b129-40f6-a07a-2c94e6604124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pathlib import Path\n",
    "from utils.filter_eval import evaluate_filter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd788e-d8f5-4621-84a5-764b6f1f59ff",
   "metadata": {},
   "source": [
    "## Constants and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "f77dba0c-506d-41f7-94e0-1f78bd80b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set background map resolutions\n",
    "azimuth_resolution = 0.1\n",
    "height_resolution = 0.25\n",
    "std_dev_cutoff = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "73db7eb6-b3f9-4a18-b7bd-a7d6d7515511",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_ROOT = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "b776a837-da24-497c-ae95-997425d96683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to true if you want to make a new distances table, otherwise, will load previous map\n",
    "# Set everything to false if you just want to filter frames\n",
    "make_new_distances_df = False\n",
    "make_new_lookup_table = False\n",
    "new_grid_search = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74dafa-7133-428b-8799-dbe0d7d67127",
   "metadata": {},
   "source": [
    "## First, functions for making background map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "2b0b2769-48b9-4b86-a127-a6ac5089a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create mappings for azimuth and height using integers\n",
    "# def create_mappings(azimuth_step=azimuth_resolution, height_step=height_resolution):\n",
    "#     azimuth_range = np.arange(-180, 180 + azimuth_step, azimuth_step)\n",
    "#     # print(azimuth_range)\n",
    "#     height_range = np.arange(-30, 10 + height_step, height_step)\n",
    "#     azimuth_map = {int(az * 10): idx for idx, az in enumerate(azimuth_range)}\n",
    "#     height_map = {int(ht * 10): idx for idx, ht in enumerate(height_range)}\n",
    "#     return azimuth_map, height_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "8cc7a47d-0512-4f9f-b963-ac8c1fcb8a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, _ = create_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "70288063-3d78-43f1-a555-1d38d09874e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "66ecb337-107d-4cf3-8faf-be3dcd1ad7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for azimuth and height using integers\n",
    "def create_mappings(azimuth_step=azimuth_resolution, height_step=height_resolution):\n",
    "    # Create ranges and multiply by 10 to convert to integers\n",
    "    azimuth_range = np.arange(-180, 180 + azimuth_step, azimuth_step) * 10\n",
    "    print(azimuth_range)\n",
    "    \n",
    "    height_range = np.arange(-30, 10 + height_step, height_step) * 10\n",
    "    \n",
    "    # Convert to integers and create dictionaries to map azimuth/height to index\n",
    "    azimuth_map = {int(az): idx for idx, az in enumerate(azimuth_range)}\n",
    "    height_map = {int(ht): idx for idx, ht in enumerate(height_range)}\n",
    "    return azimuth_map, height_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "1929e0e2-c347-4d98-983f-58da77e6815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, _ = create_mappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "39f724e2-15bf-4f35-b560-9d0d15606462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid DataFrames\n",
    "def create_grid_dataframes():\n",
    "    azimuth_map, height_map = create_mappings()\n",
    "    grid_shape = (len(height_map), len(azimuth_map))\n",
    "    df_distances = pd.DataFrame({key: [[] for _ in range(len(height_map))] \\\n",
    "                                 for key in azimuth_map.keys()}, index=height_map.keys())\n",
    "    # df_intensities = pd.DataFrame({key: [[] for _ in range(len(height_map))] \\\n",
    "                                   # for key in azimuth_map.keys()}, index=height_map.keys())\n",
    "    return df_distances, azimuth_map, height_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "e7bdd19f-2007-4f01-9aaa-bdeb654350a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df, _, _, _ = create_grid_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "c8b98ecc-b432-492e-8376-2641a91e8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "87791ed8-709c-43ec-808f-a7f735d6cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process file into grid\n",
    "# def process_files_to_grid(data_dir):\n",
    "#     # Create empty grid\n",
    "#     # df_distances, df_intensities, azimuth_map, height_map = create_grid_dataframes()\n",
    "#     df_distances, df_intensities, azimuth_map, height_map = create_grid_dataframes()\n",
    "\n",
    "#     lidar_dir = Path(data_dir, 'velodyne_points')\n",
    "\n",
    "#     # Get a list of all the file paths\n",
    "#     all_files = list(lidar_dir.iterdir())\n",
    "    \n",
    "#     # Randomly select 100 files from the list\n",
    "#     files_to_process = random.sample(all_files, 1000)\n",
    "    \n",
    "#     # For each file in the random selection\n",
    "#     for file_path in files_to_process:\n",
    "\n",
    "#     # For each file in the directory\n",
    "#     # for file_path in lidar_dir.iterdir():\n",
    "#         print('.', end ='')\n",
    "#         data = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "#         for x, y, z, intensity in data:\n",
    "#             # Convert to azimuth, height, distance format\n",
    "#             distance = np.sqrt(x**2 + y**2 + z**2)\n",
    "#             azimuth = np.degrees(np.arctan2(y, x))\n",
    "#             height = np.degrees(np.arctan2(z, np.sqrt(x**2 + y**2)))\n",
    "#             # Convert and scale\n",
    "\n",
    "#             azimuth_idx = (np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 100 - 18000).astype(int)\n",
    "#             height_idx = (np.floor((height + 30) / height_resolution) * height_resolution * 100 - 3000).astype(int)\n",
    "\n",
    "            \n",
    "#             # Update DataFrames directly using indices\n",
    "#             if azimuth_idx in azimuth_map and height_idx in height_map:\n",
    "#                 df_distances.at[height_idx, azimuth_idx].append(distance)\n",
    "#     return df_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "bfc6a48b-992a-44db-a0dc-02f5045db5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process file into grid\n",
    "def process_files_to_grid(data_dir):\n",
    "    # Create empty grid\n",
    "    # df_distances, df_intensities, azimuth_map, height_map = create_grid_dataframes()\n",
    "    df_z, azimuth_map, height_map = create_grid_dataframes()\n",
    "\n",
    "    lidar_dir = Path(data_dir, 'velodyne_points')\n",
    "\n",
    "    # Get a list of all the file paths\n",
    "    all_files = list(lidar_dir.iterdir())\n",
    "    \n",
    "    # Randomly select 100 files from the list\n",
    "    files_to_process = random.sample(all_files, 100)\n",
    "    \n",
    "    # For each file in the random selection\n",
    "    for file_path in files_to_process:\n",
    "\n",
    "    # For each file in the directory\n",
    "    # for file_path in lidar_dir.iterdir():\n",
    "        print('.', end ='')\n",
    "        data = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "        for x, y, z, intensity in data:\n",
    "            # Convert to azimuth, height, distance format\n",
    "            distance = np.sqrt(x**2 + y**2 + z**2)\n",
    "            azimuth = np.degrees(np.arctan2(y, x))\n",
    "            height = np.degrees(np.arctan2(z, np.sqrt(x**2 + y**2)))\n",
    "            # Convert and scale\n",
    "\n",
    "            azimuth_idx = (np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 10 - 1800).astype(int)\n",
    "            height_idx = (np.floor((height + 30) / height_resolution) * height_resolution * 10 - 300).astype(int)\n",
    "\n",
    "            \n",
    "            # Update DataFrames directly using indices\n",
    "            if azimuth_idx in azimuth_map and height_idx in height_map:\n",
    "                df_z.at[height_idx, azimuth_idx].append(z)\n",
    "    return df_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "f5a3047f-0ff9-48d2-b55d-32db785fa222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances_dataframe(dir):\n",
    "    # Get the distances of the background map from the lidar files\n",
    "    # if make_new_map or not files_exist(\"df_distances.pkl\", \"df_intensities.pkl\"):\n",
    "    if make_new_distances_df:\n",
    "        df_distances = process_files_to_grid(dir)\n",
    "\n",
    "        return df_distances\n",
    "    if not make_new_lookup_table:\n",
    "        print('\\nSkip loading dataframe')\n",
    "        return pd.DataFrame()\n",
    "    else:\n",
    "        # Load the DataFrames\n",
    "        print('\\nLoading dataframe')\n",
    "        df_distances = pd.read_pickle(\"df_heights.pkl\")\n",
    "        return df_distances\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "24d4269d-47cb-493e-b4ca-5b2d38c6f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_exist(*files):\n",
    "    return all(os.path.exists(file) for file in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "f812ab97-3276-4a0b-9753-f523a23cd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutoff_base(cutoff_base_param, distances):\n",
    "    if cutoff_base_param == 'average':\n",
    "        return np.mean(distances)\n",
    "    elif cutoff_base_param == 'first_quartile':\n",
    "        return np.percentile(distances, 25)\n",
    "    elif cutoff_base_param == 'median':\n",
    "        return np.median(distances)\n",
    "    elif cutoff_base_param == 'third_quartile':\n",
    "        return np.percentile(distances, 75)\n",
    "    elif cutoff_base_param == 'maximum':\n",
    "        return np.max(distances)\n",
    "    else:\n",
    "        print(cutoff_base_param + ' is not a valid cutoff_base value')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "2a3cda83-3ac4-4936-8d53-9174fe6ffa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjustment_direction_param(adjustment_direction_param, distances):\n",
    "    if adjustment_direction_param == 'add':\n",
    "        return 1\n",
    "    elif adjustment_direction_param == 'subtract':\n",
    "        return -1\n",
    "    else:\n",
    "        print(adjustment_direction_param + ' is not a valid adjustment_direction_param value')\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "e41fbb6f-1349-49b0-9fdd-3b50179bbd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjustment_parameter_param(adjustment_param, distances):\n",
    "    if adjustment_param == 'constant':\n",
    "        return 1\n",
    "    elif adjustment_param == 'standard_deviation':\n",
    "        return np.std(distances)\n",
    "    else:\n",
    "        print(adjustment_param + ' is not a valid adjustment_param value')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "2ad2f6f2-a42d-48c0-bbb8-b7bacb00fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjustment_factor_param(adjustment_factor_param, distances):\n",
    "    if adjustment_factor_param == 'average':\n",
    "        return np.mean(distances)\n",
    "    elif adjustment_factor_param == 'first_quartile':\n",
    "        return np.percentile(distances, 25)\n",
    "    elif adjustment_factor_param == 'median':\n",
    "        return np.median(distances)\n",
    "    elif adjustment_factor_param == 'third_quartile':\n",
    "        return np.percentile(distances, 75)\n",
    "    elif adjustment_factor_param == 'maximum':\n",
    "        return np.max(distances)\n",
    "    else:\n",
    "        print(adjustment_factor_param + ' is not a valid cutoff_base value')\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "e27c9a29-1f32-447a-b08f-0dcf82274fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_background_lookup_table(df_distances, cutoff_base_param='maximum', adjustment_direction_param='add', \n",
    "#                                 adjustment_param='standard_deviation', adjustment_factor=2):\n",
    "#     if make_new_lookup_table or new_grid_search:\n",
    "#         # CHANGE THIS TO USE DEFAULT OR GIVEN PARAMETERS\n",
    "#         # Create a new DataFrame with the same index and columns as df_distances\n",
    "#         lookup_table = pd.DataFrame(index=df_distances.index, columns=df_distances.columns)\n",
    "#         # Iterate through each cell in df_distances\n",
    "#         for (height, azimuth), distances in df_distances.stack().items():\n",
    "#             # If the list is not empty\n",
    "#             if distances:\n",
    "#                 # print(distances)\n",
    "#                 # Get cutoff value\n",
    "#                 # cutoff_base = get_cutoff_base(cutoff_base_param, distances)\n",
    "#                 # adj_direction = get_adjustment_direction_param(adjustment_direction_param, distances)\n",
    "#                 # adj = get_adjustment_parameter_param(adjustment_param, distances)\n",
    "                \n",
    "#                 # value = adj_direction * (adj * adjustment_factor) + cutoff_base\n",
    "#                 value = np.max(distances) - 0.5\n",
    "#                 # print(value)\n",
    "#             else:\n",
    "#                 # print('empty', end=', ')\n",
    "#                 value = np.nan  # If the list is empty, set the cell to NaN\n",
    "    \n",
    "#             # Set the value in the new DataFrame\n",
    "#             lookup_table.at[height, azimuth] = value\n",
    "\n",
    "#         if make_new_lookup_table: \n",
    "#             # Save the DataFrames\n",
    "#             print('\\nSaving lookup table')\n",
    "#             lookup_table.to_pickle(\"sample_lookup_table.pkl\")\n",
    "#     else:\n",
    "#         # Load the DataFrames\n",
    "#         print('\\nLoading lookup table')\n",
    "#         lookup_table = pd.read_pickle(\"1000_frame_min_05_lookup_table_01_25.pkl\")\n",
    "\n",
    "#     return lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "afa1b71e-2774-4acc-8aa6-2a72ec8ae559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background_lookup_table(df_z, cutoff_base_param='maximum', adjustment_direction_param='add', \n",
    "                                adjustment_param='standard_deviation', adjustment_factor=2):\n",
    "    if make_new_lookup_table or new_grid_search:\n",
    "        # CHANGE THIS TO USE DEFAULT OR GIVEN PARAMETERS\n",
    "        # Create a new DataFrame with the same index and columns as df_distances\n",
    "        lookup_table = pd.DataFrame(index=df_z.index, columns=df_z.columns)\n",
    "        # Iterate through each cell in df_distances\n",
    "        for (height, azimuth), z in df_z.stack().items():\n",
    "            # If the list is not empty\n",
    "            if z:\n",
    "                # print(distances)\n",
    "                # Get cutoff value\n",
    "                # cutoff_base = get_cutoff_base(cutoff_base_param, distances)\n",
    "                # adj_direction = get_adjustment_direction_param(adjustment_direction_param, distances)\n",
    "                # adj = get_adjustment_parameter_param(adjustment_param, distances)\n",
    "                \n",
    "                # value = adj_direction * (adj * adjustment_factor) + cutoff_base\n",
    "                value = np.percentile(z, 75)\n",
    "                # print(value)\n",
    "            else:\n",
    "                # print('empty', end=', ')\n",
    "                value = np.nan  # If the list is empty, set the cell to NaN\n",
    "    \n",
    "            # Set the value in the new DataFrame\n",
    "            lookup_table.at[height, azimuth] = value\n",
    "\n",
    "        if make_new_lookup_table: \n",
    "            # Save the DataFrames\n",
    "            print('\\nSaving lookup table')\n",
    "            lookup_table.to_pickle(\"height_lookup_table.pkl\")\n",
    "    else:\n",
    "        # Load the DataFrames\n",
    "        print('\\nLoading lookup table')\n",
    "        lookup_table = pd.read_pickle(\"height_lookup_table.pkl\")\n",
    "\n",
    "    return lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "c70de6db-794c-4f31-9d91-6619d206daf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataframe\n"
     ]
    }
   ],
   "source": [
    "dir = Path(DATA_DIR_ROOT)\n",
    "\n",
    "df_distances = get_distances_dataframe(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "579c7127-746d-4ccf-b5aa-e5a2733c15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_new_distances_df: \n",
    "    # Save the DataFrames\n",
    "    print('\\nSaving dataframe')\n",
    "    df_distances.to_pickle(\"df_heights.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61148d-ad7b-4c62-9ed0-7bd11f269b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6231c973-5d7e-476e-9fc5-44c09d4ef27c",
   "metadata": {},
   "source": [
    "## Filtering and saving functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "af930e13-e6a1-43ce-86e0-666e9f94801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(bin_path):\n",
    "    pre_filtered_data = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4) \n",
    "    columns = ['x', 'y', 'z', 'intensity']\n",
    "    df = pd.DataFrame(pre_filtered_data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "b95c4d38-7e51-4d13-8b98-8c683e7ba7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lookup_coords_to_xyz(points_df):\n",
    "    # print(points_df)\n",
    "    # Calculate the distance, azimuth, and height using vectorized operations\n",
    "    x, y, z, intensity = points_df['x'], points_df['y'], points_df['z'], points_df['intensity']\n",
    "    distance = np.sqrt(x**2 + y**2 + z**2)\n",
    "    azimuth = np.degrees(np.arctan2(y, x))\n",
    "    # print(azimuth)\n",
    "    height = np.degrees(np.arctan2(z, np.sqrt(x**2 + y**2)))\n",
    "    \n",
    "    # Convert and scale\n",
    "    azimuth_idx = (np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 10 - 1800).astype(int)\n",
    "    height_idx = (np.floor((height + 30) / height_resolution) * height_resolution * 10 - 300).astype(int)\n",
    "    \n",
    "    # Add new columns to dataframe\n",
    "    points_df['height'] = height\n",
    "    points_df['azimuth_idx'] = azimuth_idx\n",
    "    points_df['height_idx'] = height_idx\n",
    "\n",
    "    # It would be nice to also add a delta z here\n",
    "    # This would be roughly height angle / 55\n",
    "    points_df['delta_z'] = height / 55\n",
    "    \n",
    "    return points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "991b67a9-ee7e-48c5-b741-9819e4ce580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_points(frame_path, lookup_table):\n",
    "#     pre_filtered_points = convert_to_dataframe(frame_path)\n",
    "#     # Add lookup table coordinates\n",
    "#     pre_filtered_grid_lookup = add_lookup_coords_to_xyz(pre_filtered_points)\n",
    "    \n",
    "#     # Convert 'azimuth_idx' and 'height_idx' to integers\n",
    "#     pre_filtered_grid_lookup['azimuth_idx'] = pre_filtered_grid_lookup['azimuth_idx'].astype(int)\n",
    "#     pre_filtered_grid_lookup['height_idx'] = pre_filtered_grid_lookup['height_idx'].astype(int)\n",
    "    \n",
    "#     # Set index to ['height_idx', 'azimuth_idx']\n",
    "#     pre_filtered_grid_lookup_indexed = pre_filtered_grid_lookup.set_index(['height_idx', 'azimuth_idx'])\n",
    "    \n",
    "#     # Create a Series from the lookup table with a MultiIndex\n",
    "#     lookup_series = lookup_table.stack()\n",
    "    \n",
    "#     # Reindex the lookup values to align with the DataFrame's index\n",
    "#     lookup_values = lookup_series.reindex(pre_filtered_grid_lookup_indexed.index)\n",
    "    \n",
    "#     # Create a mask for indices that exist in the lookup_table\n",
    "#     indices_in_lookup = lookup_values.index.isin(lookup_series.index)\n",
    "    \n",
    "#     # Create the condition based on your filtering criteria\n",
    "#     condition = (\n",
    "#         indices_in_lookup & (\n",
    "#             lookup_values.isna() | \n",
    "#             (abs(pre_filtered_grid_lookup_indexed['x']) < abs(lookup_values) - pre_filtered_grid_lookup_indexed['delta_z']) \n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     # Apply the condition to filter the DataFrame\n",
    "#     filtered_df = pre_filtered_grid_lookup_indexed[condition].reset_index()\n",
    "    \n",
    "#     return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "320deffe-353b-49d2-98e2-f6abaca49bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def filter_points(frame_path, lookup_table):\n",
    "#     pre_filtered_points = convert_to_dataframe(frame_path)\n",
    "#     pre_filtered_grid_lookup = add_lookup_coords_to_xyz(pre_filtered_points)\n",
    "    \n",
    "#     # Convert 'azimuth_idx' and 'height_idx' to strings if necessary (depends on how they are stored in lookup_table)\n",
    "#     pre_filtered_grid_lookup['azimuth_idx'] = pre_filtered_grid_lookup['azimuth_idx'].astype(int)\n",
    "#     pre_filtered_grid_lookup['height_idx'] = pre_filtered_grid_lookup['height_idx'].astype(int)\n",
    "\n",
    "#     filtered = []\n",
    "\n",
    "#     for index, point in pre_filtered_grid_lookup.iterrows():\n",
    "#         azimuth_idx = int(point['azimuth_idx'])\n",
    "#         height_idx = int(point['height_idx'])\n",
    "\n",
    "#         # Ensure you are accessing the DataFrame by row and column labels\n",
    "#         try:\n",
    "#             bg_height = lookup_table.loc[height_idx, azimuth_idx]\n",
    "#         except KeyError:\n",
    "#             # print(f\"KeyError for indices - Height: {height_idx}, Azimuth: {azimuth_idx}\")\n",
    "#             continue\n",
    "        \n",
    "#         # Calculation and comparison using absolute values and delta_z\n",
    "#         point_effective_height = abs(point['z'] + point['delta_z'])\n",
    "#         if point_effective_height < abs(bg_height):\n",
    "#             filtered.append(point)\n",
    "        \n",
    "#         # Debugging output (optional)\n",
    "#         # print(f\"Point {index}: azimuth_idx={azimuth_idx}, height_idx={height_idx}, bg_height={bg_height}, point_height={point['height']}, delta_z={point['delta_z']}, effective_height={point_effective_height}\")\n",
    "\n",
    "#     # Return a DataFrame constructed from the filtered list\n",
    "#     return pd.DataFrame(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "c745d5b5-c1ee-4963-a76c-778d21c188eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points(frame_path, lookup_table):\n",
    "    pre_filtered_points = convert_to_dataframe(frame_path)\n",
    "    pre_filtered_grid_lookup = add_lookup_coords_to_xyz(pre_filtered_points)\n",
    "    \n",
    "    # Convert 'azimuth_idx' and 'height_idx' to integers\n",
    "    pre_filtered_grid_lookup['azimuth_idx'] = pre_filtered_grid_lookup['azimuth_idx'].astype(int)\n",
    "    pre_filtered_grid_lookup['height_idx'] = pre_filtered_grid_lookup['height_idx'].astype(int)\n",
    "\n",
    "    # Set index to ['height_idx', 'azimuth_idx'] for alignment with lookup_table\n",
    "    pre_filtered_grid_lookup.set_index(['height_idx', 'azimuth_idx'], inplace=True)\n",
    "    \n",
    "    # Flatten the lookup_table into a series with MultiIndex from its row and column indices\n",
    "    lookup_series = lookup_table.stack()\n",
    "\n",
    "    # Reindex the lookup values to align with the pre_filtered_grid_lookup index\n",
    "    lookup_values = lookup_series.reindex(pre_filtered_grid_lookup.index)\n",
    "\n",
    "    # Compute effective heights and absolute comparison within the DataFrame\n",
    "    pre_filtered_grid_lookup['effective_height'] = abs(pre_filtered_grid_lookup['z'] + pre_filtered_grid_lookup['delta_z'])\n",
    "    pre_filtered_grid_lookup['bg_height'] = lookup_values\n",
    "\n",
    "    # Filter based on condition: check where effective height is less than the background height\n",
    "    filtered_df = pre_filtered_grid_lookup[pre_filtered_grid_lookup['effective_height'] < abs(pre_filtered_grid_lookup['bg_height'])]\n",
    "\n",
    "    # Reset index if you want 'height_idx' and 'azimuth_idx' as columns\n",
    "    filtered_df = filtered_df.reset_index()\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "e77a6403-4e34-45d3-8ae4-f3ca96710410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_binary(df, bin_path):\n",
    "    try:\n",
    "        # Ensure the DataFrame is in the correct order and data type\n",
    "        data = df[['x', 'y', 'z', 'intensity']].astype(np.float32).values\n",
    "        \n",
    "        # Write the data to a binary file\n",
    "        data.tofile(bin_path)\n",
    "    except:\n",
    "        print('could not save :' + str(bin_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "9f742807-8599-44f8-a52e-7b5b14f12cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frames(source_dir, save_dir, background_lookup_table, subset_size=1):   \n",
    "    # Get just the file names\n",
    "    files = [f for f in os.listdir(source_dir) if f.endswith('.bin')]\n",
    "\n",
    "    if subset_size < 1:\n",
    "        # Get subset of files to check\n",
    "        random.shuffle(files)\n",
    "        total_files = len(files)\n",
    "        subset_num = int(total_files * subset_size)\n",
    "    else:\n",
    "        subset_num = len(files)\n",
    "    print('Filtering frames ')\n",
    "    # For each file\n",
    "    for filename in files[:subset_num]:\n",
    "        # Append file name to location\n",
    "        print(filename, end=', ')\n",
    "        from_file = Path(source_dir, filename)\n",
    "\n",
    "        # Filter file\n",
    "        filtered_df = filter_points(from_file, background_lookup_table)\n",
    "\n",
    "        # APPEND FILE NAME TO NEW LOCATION\n",
    "        to_file = Path(save_dir, filename)\n",
    "\n",
    "        # CONVERT BACK TO BINARY and save\n",
    "        save_as_binary(filtered_df, to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70999390-ce49-4fcf-b607-0f5424ca3fa8",
   "metadata": {},
   "source": [
    "## Grid search for lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "74a3f7bb-0681-4c61-8acd-a4bde7e7972f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Grid search parameters to find best lookup table\n",
    "# parameters = {\n",
    "#     'cutoff_base': ['average', 'first_quartile', 'median', 'third_quartile', 'maximum'],\n",
    "#     'adjustment_direction': ['add', 'subtract'],\n",
    "#     'adjustment_parameter': ['constant', 'standard_deviation'],\n",
    "#     'adjustment_factor': [0, 0.5, 1, 1.5, 2]\n",
    "# }\n",
    "\n",
    "parameters = {\n",
    "    'cutoff_base': ['average', 'median', 'third_quartile', 'maximum'],\n",
    "    'adjustment_direction': ['add', 'subtract'],\n",
    "    'adjustment_parameter': ['standard_deviation'],\n",
    "    'adjustment_factor': [0, 0.5, 1, 1.5, 2]\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    'cutoff_base': ['average', 'median', 'third_quartile', 'maximum'],\n",
    "    'adjustment_direction': ['add', 'subtract'],\n",
    "    'adjustment_parameter': ['standard_deviation'],\n",
    "    'adjustment_factor': [0, 0.5, 1, 1.5, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "f10ae32c-df2e-4c2d-84bf-7418a1d8d939",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate all combinations of parameters\n",
    "all_combinations = list(itertools.product(\n",
    "    parameters['cutoff_base'],\n",
    "    parameters['adjustment_direction'],\n",
    "    parameters['adjustment_parameter'],\n",
    "    parameters['adjustment_factor']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "fceb1738-359d-4015-ac2f-04a800ae9cab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('average', 'add', 'standard_deviation', 0)\n",
      "('average', 'add', 'standard_deviation', 0.5)\n",
      "('average', 'add', 'standard_deviation', 1)\n",
      "('average', 'add', 'standard_deviation', 1.5)\n",
      "('average', 'add', 'standard_deviation', 2)\n",
      "('average', 'subtract', 'standard_deviation', 0)\n",
      "('average', 'subtract', 'standard_deviation', 0.5)\n",
      "('average', 'subtract', 'standard_deviation', 1)\n",
      "('average', 'subtract', 'standard_deviation', 1.5)\n",
      "('average', 'subtract', 'standard_deviation', 2)\n",
      "('median', 'add', 'standard_deviation', 0)\n",
      "('median', 'add', 'standard_deviation', 0.5)\n",
      "('median', 'add', 'standard_deviation', 1)\n",
      "('median', 'add', 'standard_deviation', 1.5)\n",
      "('median', 'add', 'standard_deviation', 2)\n",
      "('median', 'subtract', 'standard_deviation', 0)\n",
      "('median', 'subtract', 'standard_deviation', 0.5)\n",
      "('median', 'subtract', 'standard_deviation', 1)\n",
      "('median', 'subtract', 'standard_deviation', 1.5)\n",
      "('median', 'subtract', 'standard_deviation', 2)\n",
      "('third_quartile', 'add', 'standard_deviation', 0)\n",
      "('third_quartile', 'add', 'standard_deviation', 0.5)\n",
      "('third_quartile', 'add', 'standard_deviation', 1)\n",
      "('third_quartile', 'add', 'standard_deviation', 1.5)\n",
      "('third_quartile', 'add', 'standard_deviation', 2)\n",
      "('third_quartile', 'subtract', 'standard_deviation', 0)\n",
      "('third_quartile', 'subtract', 'standard_deviation', 0.5)\n",
      "('third_quartile', 'subtract', 'standard_deviation', 1)\n",
      "('third_quartile', 'subtract', 'standard_deviation', 1.5)\n",
      "('third_quartile', 'subtract', 'standard_deviation', 2)\n",
      "('maximum', 'add', 'standard_deviation', 0)\n",
      "('maximum', 'add', 'standard_deviation', 0.5)\n",
      "('maximum', 'add', 'standard_deviation', 1)\n",
      "('maximum', 'add', 'standard_deviation', 1.5)\n",
      "('maximum', 'add', 'standard_deviation', 2)\n",
      "('maximum', 'subtract', 'standard_deviation', 0)\n",
      "('maximum', 'subtract', 'standard_deviation', 0.5)\n",
      "('maximum', 'subtract', 'standard_deviation', 1)\n",
      "('maximum', 'subtract', 'standard_deviation', 1.5)\n",
      "('maximum', 'subtract', 'standard_deviation', 2)\n"
     ]
    }
   ],
   "source": [
    "for combination in all_combinations:\n",
    "    print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "42671bbb-a16c-423a-8885-2533a544b4c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def delete_contents(folder_path):\n",
    "    # Check if the folder exists\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"Folder does not exist: {folder_path}\")\n",
    "\n",
    "    # Iterate over all files in the folder and delete them\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Removes the file or link\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "9458b476-ed96-47c8-9aa6-80d588671002",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_best_params(grid_search_results):\n",
    "    high_score = 0\n",
    "    best_key = ''\n",
    "    for param_combo_key in grid_search_results:\n",
    "        score = 2.5 * grid_search_results[param_combo_key]['results']['percent_retained_label_points'] - \\\n",
    "                                        grid_search_results[param_combo_key]['results']['percent_retained_non_label_points']\n",
    "        if score > high_score:\n",
    "            high_score = score\n",
    "            best_key = param_combo_key\n",
    "    return grid_search_results[best_key]['parameters'], best_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "53c87729-e71f-4a51-8671-cc42e5bfcde0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\velodyne_points\n"
     ]
    }
   ],
   "source": [
    "# Create a new folder for the filtered frames in the directory\n",
    "filter_save_dir = Path(DATA_DIR_ROOT, 'sample_filtered_points')\n",
    "filter_save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "lidar_dir = Path(DATA_DIR_ROOT, 'velodyne_points')\n",
    "temp_lidar_dir = Path('temp_lidar')\n",
    "temp_label_dir = Path('temp_label')\n",
    "label_dir = Path(DATA_DIR_ROOT, 'labels')\n",
    "print(lidar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "84932177-9fa7-4178-92c8-c912bb262fff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "grid_search_results = {}\n",
    "\n",
    "def find_best_lookup_table():\n",
    "    # For each combination of parameters\n",
    "    for params in all_combinations:\n",
    "        print('Checking parameters: ' + str(params))\n",
    "        # Make new lookup table\n",
    "        lookup_table = get_background_lookup_table(df_distances, \n",
    "                                                   cutoff_base_param=params[0], \n",
    "                                                   adjustment_direction_param=params[1], \n",
    "                                                   adjustment_param=params[2], \n",
    "                                                   adjustment_factor=params[3])\n",
    "        # Empty temp file\n",
    "        delete_contents('temp_lidar')\n",
    "        # delete_contents('temp_labels')\n",
    "        time.sleep(3)\n",
    "        # Filter subset of data\n",
    "        filter_frames(lidar_dir, temp_lidar_dir, lookup_table, subset_size=.01)\n",
    "        # Evaluate filtered data\n",
    "        print('\\nEvaluating results ')\n",
    "        results = evaluate_filter(temp_lidar_dir, label_dir, 'arcs_filtered')\n",
    "        print()\n",
    "        for key in results:\n",
    "            print(key + ': ' + str(results[key]))\n",
    "        print()\n",
    "\n",
    "        # Create parameter combination key\n",
    "        param_combo_key = params[0][0] + params[0][1] + '_' + params[1][0] + '_' + params[2][0] + '_' + str(params[3])\n",
    "        # Store results in results dictionary\n",
    "        grid_search_results[param_combo_key] = {'parameters': params,\n",
    "                                                'results': results}\n",
    "\n",
    "    best_params, best_params_key = get_best_params(grid_search_results)\n",
    "\n",
    "    return best_params, best_params_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "639cb573-5c95-4d31-aa22-862a1b2a4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving lookup table\n"
     ]
    }
   ],
   "source": [
    "grid_search_results = {}\n",
    "# Load, create, or use grid search to find best lookup table\n",
    "if new_grid_search:\n",
    "    best_params, best_param_key = find_best_lookup_table()\n",
    "    background_distance_lookup_table  = get_background_lookup_table(df_distances, \n",
    "                                                   cutoff_base_param=best_params[0], \n",
    "                                                   adjustment_direction_param=best_params[1], \n",
    "                                                   adjustment_param=best_params[2], \n",
    "                                                   adjustment_factor=best_params[3])\n",
    "    print('\\nSaving lookup table: ' + best_param_key)\n",
    "    background_distance_lookup_table.to_pickle('lookup_table_' + best_param_key + '.pkl')\n",
    "else:\n",
    "    # Create background lookup table for distance cutoffs\n",
    "    background_distance_lookup_table = get_background_lookup_table(df_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "760f81c7-a15d-4069-b1d2-edd637afe579",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "f7eb4a5f-b320-4b35-bbb8-cc57f6bc955b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1800</th>\n",
       "      <th>-1799</th>\n",
       "      <th>-1798</th>\n",
       "      <th>-1797</th>\n",
       "      <th>-1796</th>\n",
       "      <th>-1795</th>\n",
       "      <th>-1794</th>\n",
       "      <th>-1793</th>\n",
       "      <th>-1792</th>\n",
       "      <th>-1791</th>\n",
       "      <th>...</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>1792</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>1795</th>\n",
       "      <th>1796</th>\n",
       "      <th>1797</th>\n",
       "      <th>1798</th>\n",
       "      <th>1799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-295</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -1800 -1799 -1798 -1797 -1796 -1795 -1794 -1793 -1792 -1791  ...  1790  \\\n",
       "-300   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "-297   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "-295   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "-292   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "-290   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 90    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       " 92    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       " 95    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       " 97    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       " 100   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "\n",
       "      1791  1792  1793  1794  1795  1796  1797  1798  1799  \n",
       "-300   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "-297   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "-295   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "-292   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "-290   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       " 90    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       " 92    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       " 95    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       " 97    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       " 100   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[161 rows x 3600 columns]"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_distance_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "3f4c1335-10b0-4824-b94e-9f34903f604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilya\\AppData\\Local\\Temp\\ipykernel_1640\\2900473312.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  filled_lookup_table = background_distance_lookup_table.ffill(axis=0).bfill(axis=0)  # Fill along rows\n"
     ]
    }
   ],
   "source": [
    "# filled_lookup_table = background_distance_lookup_table.fillna(method='ffill', axis=0).fillna(method='bfill', axis=0)  # Fill along rows\n",
    "# filled_lookup_table = filled_lookup_table.fillna(method='ffill', axis=1).fillna(method='bfill', axis=1) \n",
    "filled_lookup_table = background_distance_lookup_table.ffill(axis=0).bfill(axis=0)  # Fill along rows\n",
    "filled_lookup_table = filled_lookup_table.ffill(axis=1).bfill(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "d4783372-4e8c-4bd6-bbba-7d40b1c98adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1800</th>\n",
       "      <th>-1799</th>\n",
       "      <th>-1798</th>\n",
       "      <th>-1797</th>\n",
       "      <th>-1796</th>\n",
       "      <th>-1795</th>\n",
       "      <th>-1794</th>\n",
       "      <th>-1793</th>\n",
       "      <th>-1792</th>\n",
       "      <th>-1791</th>\n",
       "      <th>...</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>1792</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>1795</th>\n",
       "      <th>1796</th>\n",
       "      <th>1797</th>\n",
       "      <th>1798</th>\n",
       "      <th>1799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-300</th>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.564618</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.575606</td>\n",
       "      <td>-0.557011</td>\n",
       "      <td>-1.616093</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.546023</td>\n",
       "      <td>-0.600118</td>\n",
       "      <td>-0.844814</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621164</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.354069</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.555321</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.561237</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-1.614825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-297</th>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.564618</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.575606</td>\n",
       "      <td>-0.557011</td>\n",
       "      <td>-1.616093</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.546023</td>\n",
       "      <td>-0.600118</td>\n",
       "      <td>-0.844814</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621164</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.354069</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.555321</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.561237</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-1.614825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-295</th>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.564618</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.575606</td>\n",
       "      <td>-0.557011</td>\n",
       "      <td>-1.616093</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.546023</td>\n",
       "      <td>-0.600118</td>\n",
       "      <td>-0.844814</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621164</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.354069</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.555321</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.561237</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-1.614825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-292</th>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.564618</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.575606</td>\n",
       "      <td>-0.557011</td>\n",
       "      <td>-1.616093</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.546023</td>\n",
       "      <td>-0.600118</td>\n",
       "      <td>-0.844814</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621164</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.354069</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.555321</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.561237</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-1.614825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-290</th>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.564618</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.575606</td>\n",
       "      <td>-0.557011</td>\n",
       "      <td>-1.616093</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.546023</td>\n",
       "      <td>-0.600118</td>\n",
       "      <td>-0.844814</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.621164</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.354069</td>\n",
       "      <td>-0.549404</td>\n",
       "      <td>-1.363367</td>\n",
       "      <td>-0.555321</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-0.561237</td>\n",
       "      <td>-1.617783</td>\n",
       "      <td>-1.614825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.806288</td>\n",
       "      <td>0.805313</td>\n",
       "      <td>0.804338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.820912</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.814575</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.812625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.806288</td>\n",
       "      <td>0.805313</td>\n",
       "      <td>0.804338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.820912</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.814575</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.812625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.806288</td>\n",
       "      <td>0.805313</td>\n",
       "      <td>0.804338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.820912</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.814575</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.812625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.806288</td>\n",
       "      <td>0.805313</td>\n",
       "      <td>0.804338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.820912</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.814575</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.812625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.809213</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.807263</td>\n",
       "      <td>0.806288</td>\n",
       "      <td>0.805313</td>\n",
       "      <td>0.804338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821887</td>\n",
       "      <td>0.820912</td>\n",
       "      <td>0.819450</td>\n",
       "      <td>0.818475</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.816525</td>\n",
       "      <td>0.815550</td>\n",
       "      <td>0.814575</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.812625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         -1800     -1799     -1798     -1797     -1796     -1795     -1794  \\\n",
       "-300 -1.363367 -0.564618 -1.617783 -0.575606 -0.557011 -1.616093 -1.617783   \n",
       "-297 -1.363367 -0.564618 -1.617783 -0.575606 -0.557011 -1.616093 -1.617783   \n",
       "-295 -1.363367 -0.564618 -1.617783 -0.575606 -0.557011 -1.616093 -1.617783   \n",
       "-292 -1.363367 -0.564618 -1.617783 -0.575606 -0.557011 -1.616093 -1.617783   \n",
       "-290 -1.363367 -0.564618 -1.617783 -0.575606 -0.557011 -1.616093 -1.617783   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 90   0.812625  0.811650  0.810675  0.809700  0.809213  0.808238  0.807263   \n",
       " 92   0.812625  0.811650  0.810675  0.809700  0.809213  0.808238  0.807263   \n",
       " 95   0.812625  0.811650  0.810675  0.809700  0.809213  0.808238  0.807263   \n",
       " 97   0.812625  0.811650  0.810675  0.809700  0.809213  0.808238  0.807263   \n",
       " 100  0.812625  0.811650  0.810675  0.809700  0.809213  0.808238  0.807263   \n",
       "\n",
       "         -1793     -1792     -1791  ...      1790      1791      1792  \\\n",
       "-300 -0.546023 -0.600118 -0.844814  ... -1.621164 -0.549404 -1.354069   \n",
       "-297 -0.546023 -0.600118 -0.844814  ... -1.621164 -0.549404 -1.354069   \n",
       "-295 -0.546023 -0.600118 -0.844814  ... -1.621164 -0.549404 -1.354069   \n",
       "-292 -0.546023 -0.600118 -0.844814  ... -1.621164 -0.549404 -1.354069   \n",
       "-290 -0.546023 -0.600118 -0.844814  ... -1.621164 -0.549404 -1.354069   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       " 90   0.806288  0.805313  0.804338  ...  0.821887  0.820912  0.819450   \n",
       " 92   0.806288  0.805313  0.804338  ...  0.821887  0.820912  0.819450   \n",
       " 95   0.806288  0.805313  0.804338  ...  0.821887  0.820912  0.819450   \n",
       " 97   0.806288  0.805313  0.804338  ...  0.821887  0.820912  0.819450   \n",
       " 100  0.806288  0.805313  0.804338  ...  0.821887  0.820912  0.819450   \n",
       "\n",
       "          1793      1794      1795      1796      1797      1798      1799  \n",
       "-300 -0.549404 -1.363367 -0.555321 -1.617783 -0.561237 -1.617783 -1.614825  \n",
       "-297 -0.549404 -1.363367 -0.555321 -1.617783 -0.561237 -1.617783 -1.614825  \n",
       "-295 -0.549404 -1.363367 -0.555321 -1.617783 -0.561237 -1.617783 -1.614825  \n",
       "-292 -0.549404 -1.363367 -0.555321 -1.617783 -0.561237 -1.617783 -1.614825  \n",
       "-290 -0.549404 -1.363367 -0.555321 -1.617783 -0.561237 -1.617783 -1.614825  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 90   0.818475  0.817500  0.816525  0.815550  0.814575  0.813600  0.812625  \n",
       " 92   0.818475  0.817500  0.816525  0.815550  0.814575  0.813600  0.812625  \n",
       " 95   0.818475  0.817500  0.816525  0.815550  0.814575  0.813600  0.812625  \n",
       " 97   0.818475  0.817500  0.816525  0.815550  0.814575  0.813600  0.812625  \n",
       " 100  0.818475  0.817500  0.816525  0.815550  0.814575  0.813600  0.812625  \n",
       "\n",
       "[161 rows x 3600 columns]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "7c585a94-0e3f-4ae3-a380-d8c814bb7d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([-300, -297, -295, -292, -290, -287, -285, -282, -280, -277,\n",
      "       ...\n",
      "         77,   80,   82,   85,   87,   90,   92,   95,   97,  100],\n",
      "      dtype='int64', length=161)\n",
      "Index([-1800, -1799, -1798, -1797, -1796, -1795, -1794, -1793, -1792, -1791,\n",
      "       ...\n",
      "        1790,  1791,  1792,  1793,  1794,  1795,  1796,  1797,  1798,  1799],\n",
      "      dtype='int64', length=3600)\n"
     ]
    }
   ],
   "source": [
    "print(filled_lookup_table.index)\n",
    "print(filled_lookup_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "f7d44ac6-1229-4c91-862c-18a44cfccd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering frames \n",
      "001351.bin, 005940.bin, 003242.bin, 004679.bin, "
     ]
    }
   ],
   "source": [
    "# Filter and save each filtered frame\n",
    "# save_dir = Path(DATA_DIR_ROOT, 'test_folder')\n",
    "save_dir = Path(DATA_DIR_ROOT, 'filtered_points')\n",
    "# filter_frames(lidar_dir, save_dir, filled_lookup_table, subset_size=0.001)\n",
    "filter_frames(lidar_dir, save_dir, filled_lookup_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
