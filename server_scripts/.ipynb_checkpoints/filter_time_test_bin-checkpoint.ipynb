{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841e6b10",
   "metadata": {},
   "source": [
    "# Test the filter time for binary files in azimuth, height, distance format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0a9bc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import njit, prange\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from contextlib import redirect_stdout\n",
    "from mmdet3d.apis import LidarDet3DInferencer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e50a3",
   "metadata": {},
   "source": [
    "## May need to change back the lon values in the numba library\n",
    "File ~/miniconda3/envs/openmm_mmvc/lib/python3.8/site-packages/numba/core/types/__init__.py:110<br>\n",
    "    108 # long_ = _make_signed(np.long)<br>\n",
    "    109 long_ = _make_signed(np.int_)<br>\n",
    "--> 110 ulong = _make_unsigned(np.long)<br>\n",
    "    111 longlong = _make_signed(np.longlong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c1c288f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachel/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n",
      "/home/rachel/miniconda3/envs/openmm_mmvc/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    }
   ],
   "source": [
    "# Initialize inferencer\n",
    "inferencer = LidarDet3DInferencer('pointpillars_kitti-3class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5dab88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "azimuth_resolution = 0.05\n",
    "height_resolution = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f559a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b850d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9afa03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(bin_path):\n",
    "    pre_filtered_data = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4) \n",
    "    columns = ['azimuth', 'height', 'distance', 'intensity']\n",
    "    df = pd.DataFrame(pre_filtered_data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ea54f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of dataframes of LiDAR points\n",
    "def get_frames(source_dir, num_frames):\n",
    "    frame_list = []\n",
    "    \n",
    "    # Get frame names\n",
    "    files = [f for f in os.listdir(source_dir) if f.endswith('.bin')]\n",
    "    # Shuffle and take desired number of files\n",
    "    random.shuffle(files)\n",
    "    files = files[:num_frames]\n",
    "    \n",
    "    # For each frame\n",
    "    for file in files:\n",
    "        print('.', end='')\n",
    "        file_path = Path(source_dir, file)\n",
    "        # Load each frame\n",
    "        frame_list.append(convert_to_dataframe(file_path))\n",
    "        \n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee8bb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle background map dataframe and fill the empty values\n",
    "def get_filter(background_map_path):\n",
    "    background_distance_lookup_table = pd.read_pickle(background_map_path)\n",
    "    filled_lookup_table = background_distance_lookup_table.ffill(axis=0).bfill(axis=0)\n",
    "    filled_lookup_table = filled_lookup_table.ffill(axis=1).bfill(axis=1)\n",
    "    return filled_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2b7ad565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lookup_coords_to_ahd(points_df):\n",
    "    # print(points_df)\n",
    "    # Calculate the distance, azimuth, and height using vectorized operations\n",
    "    azimuth, height, distance, intensity = points_df['azimuth'], points_df['height'], points_df['distance'], points_df['intensity']\n",
    "    \n",
    "    # Convert and scale\n",
    "    azimuth_idx = (np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 100 - 18000).astype(int)\n",
    "    height_idx = (np.floor((height + 30) / height_resolution) * height_resolution * 100 - 3000).astype(int)\n",
    "\n",
    "    points_df['azimuth_idx'] = azimuth_idx\n",
    "    points_df['height_idx'] = height_idx\n",
    "    \n",
    "    return points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "61728943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frame(pre_filtered_points, lookup_table):\n",
    "    # Add lookup table coordinates\n",
    "    pre_filtered_grid_lookup = add_lookup_coords_to_ahd(pre_filtered_points)\n",
    "    \n",
    "    # Set index to ['height_idx', 'azimuth_idx']\n",
    "    pre_filtered_grid_lookup_indexed = pre_filtered_grid_lookup.set_index(['height_idx', 'azimuth_idx'])\n",
    "    \n",
    "    # Create a Series from the lookup table with a MultiIndex\n",
    "    lookup_series = lookup_table.stack()\n",
    "    \n",
    "    # Reindex the lookup values to align with the DataFrame's index\n",
    "    lookup_values = lookup_series.reindex(pre_filtered_grid_lookup_indexed.index)\n",
    "    \n",
    "    # Create a mask for indices that exist in the lookup_table\n",
    "    indices_in_lookup = lookup_values.index.isin(lookup_series.index)\n",
    "    \n",
    "    # Create the condition based on filtering criteria\n",
    "    condition = (\n",
    "        indices_in_lookup & (\n",
    "            lookup_values.isna() | \n",
    "            (pre_filtered_grid_lookup_indexed['distance'] < lookup_values)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Apply the condition to filter the DataFrame\n",
    "    filtered_df = pre_filtered_grid_lookup_indexed[condition].reset_index()\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4ee589a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xyz(points_df):\n",
    "    azimuth, height, distance, intensity = points_df['azimuth'], points_df['height'], points_df['distance'], points_df['intensity']\n",
    "    \n",
    "    azimuth_rad = np.deg2rad(azimuth)\n",
    "    height_rad = np.deg2rad(height)\n",
    "    x = distance * np.cos(height_rad) * np.sin(azimuth_rad)\n",
    "    y = distance * np.cos(height_rad) * np.cos(azimuth_rad)\n",
    "    z = distance * np.sin(height_rad)\n",
    "    \n",
    "    # Stack the computed values into a numpy array\n",
    "    xyz_intensity_array = np.column_stack((x, y, z, intensity))\n",
    "    \n",
    "    return xyz_intensity_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dcb02806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_filter(lidar_frames_list, filter_df, filter_points=True):\n",
    "    # Start timer\n",
    "    start = time.time()\n",
    "    # For each frame\n",
    "    for frame_df in lidar_frames_list:\n",
    "        # Filter frame\n",
    "        if filter_points:\n",
    "            frame_df = filter_frame(frame_df, filter_df)\n",
    "        # Convert to x, y, z\n",
    "        xyz_frame = convert_to_xyz(frame_df)\n",
    "        \n",
    "        # Run Inferences\n",
    "        inferencer(dict(points=xyz_frame))\n",
    "    # Stop timer\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1e65f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(data_dir, background_map_path, num_frames):\n",
    "    # Get dataframes\n",
    "    lidar_frames_list = get_frames(data_dir, num_frames)\n",
    "    filter_df = get_filter(background_map_path)\n",
    "    \n",
    "    total_time_filter = time_filter(lidar_frames_list, filter_df)\n",
    "    \n",
    "    total_time_no_filter = time_filter(lidar_frames_list, pd.DataFrame(), filter_points=False)\n",
    "    \n",
    "    results_filter = {\n",
    "        'type': 'filtered',\n",
    "        'num_frames': num_frames,\n",
    "        'total_time': total_time_filter,\n",
    "        'time_per_frame': total_time_filter / num_frames\n",
    "    }\n",
    "    \n",
    "    results_no_filter = {\n",
    "        'type': 'not filtered',\n",
    "        'num_frames': num_frames,\n",
    "        'total_time': total_time_no_filter,\n",
    "        'time_per_frame': total_time_no_filter / num_frames\n",
    "    }\n",
    "    return [results_filter, results_no_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "37c0cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/az_height_dist_points'\n",
    "background_map_path = '../data/lookup_table.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3653ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run time test and get results\n",
    "time_results = run_test(data_dir, background_map_path, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c9e63dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_per_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>filtered</td>\n",
       "      <td>200</td>\n",
       "      <td>34.681064</td>\n",
       "      <td>0.173405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not filtered</td>\n",
       "      <td>200</td>\n",
       "      <td>17.203532</td>\n",
       "      <td>0.086018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           type  num_frames  total_time  time_per_frame\n",
       "0      filtered         200   34.681064        0.173405\n",
       "1  not filtered         200   17.203532        0.086018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(time_results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a725c",
   "metadata": {},
   "source": [
    "# Numba versions of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a267b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_np_array(bin_path):\n",
    "    pre_filtered_data = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4) \n",
    "    return pre_filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92c19244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of frames of LiDAR points\n",
    "def get_frames(source_dir, num_frames):\n",
    "    frame_list = []\n",
    "    \n",
    "    # Get frame names\n",
    "    files = [f for f in os.listdir(source_dir) if f.endswith('.bin')]\n",
    "    # Shuffle and take desired number of files\n",
    "    random.shuffle(files)\n",
    "    files = files[:num_frames]\n",
    "    \n",
    "    # For each frame\n",
    "    for file in files:\n",
    "        print('.', end='')\n",
    "        file_path = Path(source_dir, file)\n",
    "        # Load each frame\n",
    "        frame_list.append(convert_to_np_array(file_path))\n",
    "        \n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cec72f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle background map dataframe and fill the empty values\n",
    "def get_filter(background_map_path):\n",
    "    background_distance_lookup_table = pd.read_pickle(background_map_path)\n",
    "    filled_lookup_table = background_distance_lookup_table.ffill(axis=0).bfill(axis=0)\n",
    "    filled_lookup_table = filled_lookup_table.ffill(axis=1).bfill(axis=1)\n",
    "    return filled_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "be6e3bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def compute_lookup_coords(azimuth, height):\n",
    "    azimuth_idx = np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 100 - 18000\n",
    "    height_idx = np.floor((height + 30) / height_resolution) * height_resolution * 100 - 3000\n",
    "\n",
    "    azimuth_idx = azimuth_idx.astype(np.int32)\n",
    "    height_idx = height_idx.astype(np.int32)\n",
    "\n",
    "    return azimuth_idx, height_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dd98632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lookup_coords_to_ahd(np_frame):\n",
    "    # Extract columns from np_frame\n",
    "    azimuth = np_frame[:, 0]\n",
    "    height = np_frame[:, 1]\n",
    "    distance = np_frame[:, 2]\n",
    "    intensity = np_frame[:, 3]\n",
    "\n",
    "    # Compute indices using the Numba-accelerated function\n",
    "    azimuth_idx, height_idx = compute_lookup_coords(azimuth, height)\n",
    "\n",
    "    # Stack the new indices onto the original data\n",
    "    # The result will be a NumPy array with shape (n_samples, 6)\n",
    "    augmented_frame = np.column_stack((azimuth, height, distance, intensity, azimuth_idx, height_idx))\n",
    "\n",
    "    return augmented_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b1e10c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def filter_points_numba(distance, azimuth_idx, height_idx, lookup_values_array, height_indices, azimuth_indices):\n",
    "    num_points = len(distance)\n",
    "    filtered_mask = np.zeros(num_points, dtype=np.bool_)\n",
    "\n",
    "    for i in prange(num_points):\n",
    "        h_idx = height_idx[i]\n",
    "        a_idx = azimuth_idx[i]\n",
    "\n",
    "        # Find positions using searchsorted\n",
    "        h_pos = np.searchsorted(height_indices, h_idx)\n",
    "        a_pos = np.searchsorted(azimuth_indices, a_idx)\n",
    "\n",
    "        # Check if indices are within bounds and match the desired indices\n",
    "        if h_pos < len(height_indices) and height_indices[h_pos] == h_idx and \\\n",
    "           a_pos < len(azimuth_indices) and azimuth_indices[a_pos] == a_idx:\n",
    "            lookup_value = lookup_values_array[h_pos, a_pos]\n",
    "            if not np.isnan(lookup_value):\n",
    "                if distance[i] < lookup_value:\n",
    "                    filtered_mask[i] = True\n",
    "            else:\n",
    "                filtered_mask[i] = True  # Include if lookup_value is NaN\n",
    "        else:\n",
    "            # Indices not found in lookup table; decide whether to include or exclude\n",
    "            filtered_mask[i] = False  # Exclude by default\n",
    "\n",
    "    return filtered_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5714492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frame(np_frame, lookup_table):\n",
    "    # Add lookup coordinates\n",
    "    augmented_frame = add_lookup_coords_to_ahd(np_frame)\n",
    "\n",
    "    # Extract the necessary columns\n",
    "    distance = augmented_frame[:, 2]\n",
    "    azimuth_idx = augmented_frame[:, 4].astype(np.int32)\n",
    "    height_idx = augmented_frame[:, 5].astype(np.int32)\n",
    "\n",
    "    # Convert the lookup table to NumPy arrays\n",
    "    lookup_values_array = lookup_table.values.copy()\n",
    "    height_indices = lookup_table.index.values.copy()\n",
    "    azimuth_indices = lookup_table.columns.values.copy()\n",
    "\n",
    "    # Make sure the indices are sorted and reorder the lookup values accordingly\n",
    "    height_sort_order = np.argsort(height_indices)\n",
    "    height_indices = height_indices[height_sort_order]\n",
    "    lookup_values_array = lookup_values_array[height_sort_order, :]\n",
    "\n",
    "    azimuth_sort_order = np.argsort(azimuth_indices)\n",
    "    azimuth_indices = azimuth_indices[azimuth_sort_order]\n",
    "    lookup_values_array = lookup_values_array[:, azimuth_sort_order]\n",
    "\n",
    "    # Apply the Numba filtering function\n",
    "    filtered_mask = filter_points_numba(distance, azimuth_idx, height_idx,\n",
    "                                        lookup_values_array, height_indices, azimuth_indices)\n",
    "\n",
    "    # Apply the mask to the original data\n",
    "    filtered_data = augmented_frame[filtered_mask]\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7f95ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def convert_to_xyz_numba(azimuth, height, distance, intensity):\n",
    "    # Convert degrees to radians\n",
    "    azimuth_rad = np.deg2rad(azimuth)\n",
    "    height_rad = np.deg2rad(height)\n",
    "\n",
    "    # Precompute trigonometric functions\n",
    "    cos_height = np.cos(height_rad)\n",
    "    sin_height = np.sin(height_rad)\n",
    "    sin_azimuth = np.sin(azimuth_rad)\n",
    "    cos_azimuth = np.cos(azimuth_rad)\n",
    "\n",
    "    # Compute x, y, z\n",
    "    x = distance * cos_height * sin_azimuth\n",
    "    y = distance * cos_height * cos_azimuth\n",
    "    z = distance * sin_height\n",
    "\n",
    "    # Stack the computed values into a numpy array\n",
    "    xyz_intensity_array = np.column_stack((x, y, z, intensity))\n",
    "\n",
    "    return xyz_intensity_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "af7c94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xyz(np_frame):\n",
    "    # Extract columns from np_frame\n",
    "    azimuth = np_frame[:, 0]\n",
    "    height = np_frame[:, 1]\n",
    "    distance = np_frame[:, 2]\n",
    "    intensity = np_frame[:, 3]\n",
    "\n",
    "    # Call the Numba-accelerated function\n",
    "    xyz_intensity_array = convert_to_xyz_numba(azimuth, height, distance, intensity)\n",
    "\n",
    "    return xyz_intensity_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "156c6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_binary(np_array, bin_path):\n",
    "    try:\n",
    "        # Ensure the array is in float32 type\n",
    "        data = np_array.astype(np.float32)\n",
    "        \n",
    "        # Write the data to a binary file\n",
    "        data.tofile(bin_path)\n",
    "    except Exception as e:\n",
    "        print('Could not save:', bin_path)\n",
    "        print('Error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "33933953",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../data/test'\n",
    "def time_filter(lidar_frames_list, filter_df, filter_points=True):\n",
    "    # Start timer\n",
    "    start = time.time()\n",
    "    # For each frame\n",
    "    for index, frame_np in enumerate(lidar_frames_list):\n",
    "        # Filter frame\n",
    "        if filter_points:\n",
    "            frame_np = filter_frame(frame_np, filter_df)\n",
    "        # Convert to x, y, z\n",
    "        xyz_frame = convert_to_xyz(frame_np)\n",
    "        \n",
    "        # Run Inferences\n",
    "        inferencer(dict(points=xyz_frame))\n",
    "    # Stop timer\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4e76d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(data_dir, background_map_path, num_frames):\n",
    "    # Get dataframes\n",
    "    lidar_frames_list = get_frames(data_dir, num_frames)\n",
    "    filter_df = get_filter(background_map_path)\n",
    "    \n",
    "    total_time_filter = time_filter(lidar_frames_list, filter_df)\n",
    "    \n",
    "    total_time_no_filter = time_filter(lidar_frames_list, pd.DataFrame(), filter_points=False)\n",
    "    \n",
    "    results_filter = {\n",
    "        'type': 'filtered',\n",
    "        'num_frames': num_frames,\n",
    "        'total_time': total_time_filter,\n",
    "        'time_per_frame': total_time_filter / num_frames\n",
    "    }\n",
    "    \n",
    "    results_no_filter = {\n",
    "        'type': 'not filtered',\n",
    "        'num_frames': num_frames,\n",
    "        'total_time': total_time_no_filter,\n",
    "        'time_per_frame': total_time_no_filter / num_frames\n",
    "    }\n",
    "    return [results_filter, results_no_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6098f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/az_height_dist_points'\n",
    "background_map_path = '../data/lookup_table.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6a1b35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run time test and get results\n",
    "time_results = run_test(data_dir, background_map_path, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "510982ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>total_time</th>\n",
       "      <th>time_per_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>filtered</td>\n",
       "      <td>200</td>\n",
       "      <td>16.605084</td>\n",
       "      <td>0.083025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not filtered</td>\n",
       "      <td>200</td>\n",
       "      <td>18.230908</td>\n",
       "      <td>0.091155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           type  num_frames  total_time  time_per_frame\n",
       "0      filtered         200   16.605084        0.083025\n",
       "1  not filtered         200   18.230908        0.091155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(time_results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
