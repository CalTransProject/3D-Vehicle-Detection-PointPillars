{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c387c7",
   "metadata": {},
   "source": [
    "# Test PointPillars on ARCS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e8c3ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import bbox\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contextlib import redirect_stdout\n",
    "from mmdet3d.apis import LidarDet3DInferencer\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e357ce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth\n"
     ]
    }
   ],
   "source": [
    "# Initialize inferencer\n",
    "inferencer = LidarDet3DInferencer('pointpillars_kitti-3class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4af4f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths\n",
    "ARCS_LABELS = '../data/eval_data/labels'\n",
    "ARCS_DATA_DIR = '../data/eval_data/arcs'\n",
    "ARCS_FILTERED_DATA_DIR = '../data/eval_data/arcs_azimuth_filtered'\n",
    "ARCS_LABEL_FILTERED_DATA_DIR = '../data/eval_data/arcs_label_filtered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0669b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3D bbox object requires quaternion values. This function converts the yaw to these values\n",
    "def yaw_to_quaternion(yaw):\n",
    "    \"\"\"\n",
    "    Converts a yaw angle (rotation about the z-axis) to quaternion coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    - yaw (float): The yaw angle in radians.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple of (rw, rx, ry, rz): The quaternion representation of the yaw.\n",
    "    \"\"\"\n",
    "    # Compute the components of the quaternion\n",
    "    rw = math.cos(yaw / 2.0)\n",
    "    rz = math.sin(yaw / 2.0)\n",
    "    \n",
    "    # rx and ry are zero because the rotation is only about the z-axis\n",
    "    return (rw, 0, 0, rz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d73fe0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes x, y, z, dx, dy, dz, yaw and returns a 3D bbox object from the bbox package\n",
    "# Yaw is in radians\n",
    "def get3DBbox(x, y, z, dx, dy, dz, yaw):\n",
    "    # Example usage:\n",
    "    rw, rx, ry, rz = yaw_to_quaternion(yaw)\n",
    "    bbox_obj = bbox.BBox3D(x, y, z, length=dx, width=dy, height=dz, rw=rw, rx=rx, ry=ry, rz=rz)\n",
    "    return bbox_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a9f11929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(bbox1, bbox2):\n",
    "    bbox_obj1 = get3DBbox(*bbox1)\n",
    "    bbox_obj2 = get3DBbox(*bbox2)\n",
    "    return bbox.metrics.jaccard_index_3d(bbox_obj1, bbox_obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5e488df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _evaluate frame takes a prediction dictionary output by the model, and a list of ground truths\n",
    "# from the label file, and returns the TPs, FPs, and FNs for one lidar frame\n",
    "def _evaluate_frame(predictions, ground_truths, threshold=0.25):\n",
    "    TPs, FPs, FNs = 0, 0, len(ground_truths)\n",
    "    used_gt = set()\n",
    "    \n",
    "    for pred in predictions['predictions']:\n",
    "        for label, score, bbox in zip(pred['labels_3d'], pred['scores_3d'], pred['bboxes_3d']):\n",
    "            if score < threshold:\n",
    "                continue\n",
    "\n",
    "            best_iou = 0\n",
    "            best_gt = None\n",
    "            for gt in ground_truths:\n",
    "                iou = calculate_iou(bbox, gt[8:])\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt = tuple(gt)\n",
    "\n",
    "            if best_iou > threshold:  # Example IoU threshold for a match\n",
    "                if best_gt not in used_gt:\n",
    "                    used_gt.add(best_gt)\n",
    "                    TPs += 1\n",
    "                    FNs -= 1\n",
    "                else:\n",
    "                    FPs += 1\n",
    "            else:\n",
    "                FPs += 1\n",
    "    return TPs, FPs, FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "79907699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ground_truths(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            bbox = []\n",
    "            # Add the category as a string\n",
    "            bbox.append(parts[0])\n",
    "            # Extract the bounding box dimensions and location as \n",
    "            bbox = bbox + [float(value) for value in parts[1:15]]  \n",
    "            bbox[2] = int(bbox[2])\n",
    "            labels.append(bbox)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8660b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_problem_file_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e7c4cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _evaluate frame takes a lidar and label file path and\n",
    "# and returns the TPs, FPs, and FNs for one lidar frame\n",
    "def evaluate_frame(lidar_file_path, label_file_path):\n",
    "    inputs = dict(points=str(lidar_file_path))\n",
    "    \n",
    "    # Get predictions\n",
    "    try:\n",
    "        predictions = inferencer(inputs)\n",
    "            # Get ground truths\n",
    "        ground_truths = parse_ground_truths(label_file_path)\n",
    "\n",
    "        TPs, FPs, FNs = _evaluate_frame(predictions, ground_truths)\n",
    "    except:\n",
    "        # Add file id to the problem file list\n",
    "        print(str(lidar_file_path))\n",
    "        lidar_filename = os.path.basename(lidar_file_path)\n",
    "        file_id, extension = os.path.splitext(lidar_filename)\n",
    "        generated_problem_file_list.append(file_id)\n",
    "        TPs, FPs, FNs = 0, 0, 0\n",
    "    \n",
    "    return TPs, FPs, FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "beec6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem files. I'll find out why later\n",
    "problem_file_ids = ['002928', '005318', '004397', '004254', '001747', '005399', '005871', '000869', '001084', '004098',\n",
    "                    '002183', '000447', '004096', '000312', '002188', '000829', '002181', '004930', '004095', '000448', \n",
    "                    '005320', '000157', '001764', '002610', '005875', '006445', '003709', '002613', '002624', '004359', \n",
    "                    '002186', '000769', '005231', '004348', '001658', '006287', '005874', '005319', '002411', '005321', \n",
    "                    '002187', '005872', '002184', '000666', '001085', '005324', '004292', '003710', '003068', '006129', \n",
    "                    '004055', '001512', '002410', '001777', '004931', '002399', '000706', '002622', '005255', '005158', \n",
    "                    '002185', '001746', '001779', '003148', '006130', '003441', '004398', '005873', '002621', '004932', \n",
    "                    '001580', '003400', '000311', '004293', '001702', '004054', '000356', '005323', '000154', '004358', \n",
    "                    '005254', '004017', '004097', '000313', '003399', '006249', '004349', '001765', '000315', '002623', \n",
    "                    '005322', '000028', '001068', '001529', '001778', '002190', '004253', '000156', '000354', '000317', \n",
    "                    '002189', '000316', '000155', '003442', '000353', '002182', '000153', '003247', '002609', '000355', \n",
    "                    '004018', '005238', '005159', '000314']\n",
    "okay_file_ids = ['001731', '005977', '005368', '005924', '004402']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "87e82308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(list_file_ids):\n",
    "    for id in list_file_ids:\n",
    "        print(f'\\n_____________________________________________________________')\n",
    "        \n",
    "        file_path = f'{ARCS_LABEL_FILTERED_DATA_DIR}/{id}.bin'\n",
    "        label_path = f'{ARCS_LABELS}/{id}.txt' \n",
    "\n",
    "        # Open point cloud file\n",
    "        points = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "        df_points = pd.DataFrame(points, columns=['x', 'y', 'z', 'intensity'])\n",
    "\n",
    "        # Print the DataFrame summary\n",
    "        print(f\"Summary for file ID {id}:\")\n",
    "        print('length: ' + str(len(df_points)))\n",
    "        print(\"DataFrame Info:\")\n",
    "        df_points.info()\n",
    "        print(\"\\nDataFrame Description:\")\n",
    "        print(df_points.describe())\n",
    "        print(f'\\nlabels:')\n",
    "        # Print labels\n",
    "        with open(label_path, 'r') as file:\n",
    "            for line in file:\n",
    "                print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6e8ce213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_summary(problem_file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1d7d372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_summary(okay_file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ff7fb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(dataset_path):\n",
    "    label_dir = Path(ARCS_LABELS)\n",
    "    dataset_dir = Path(dataset_path)\n",
    "    \n",
    "    total_TPs, total_FPs, total_FNs = 0, 0, 0\n",
    "\n",
    "#     for bin_file in itertools.islice(dataset_dir.iterdir(), 1000):\n",
    "    for bin_file in dataset_dir.iterdir():\n",
    "        if str(bin_file).endswith('.bin'):\n",
    "            print('.', end='')\n",
    "\n",
    "            lidar_filename = os.path.basename(bin_file)\n",
    "            # Split the filename from the extension ('006428', '.txt')\n",
    "            file_id, extension = os.path.splitext(lidar_filename)\n",
    "            if file_id not in problem_file_ids:\n",
    "                label_filename = file_id + '.txt'\n",
    "\n",
    "                # Make file paths\n",
    "                lidar_file_path = Path(dataset_dir, lidar_filename)\n",
    "                label_file_path = Path(label_dir, label_filename)\n",
    "                \n",
    "                print('evaluating: ' + str(lidar_file_path))\n",
    "                \n",
    "                TPs, FPs, FNs = evaluate_frame(lidar_file_path, label_file_path)\n",
    "\n",
    "                total_TPs += TPs\n",
    "                total_FPs += FPs\n",
    "                total_FNs += FNs\n",
    "            else:\n",
    "                print('skipping ' + file_id)\n",
    "            \n",
    "    return total_TPs, total_FPs, total_FNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0dbdf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pointpillars(dataset_path):\n",
    "    print('Evaluating dataset: ' + dataset_path)\n",
    "    # Get all TP, FP, and FN in the dataset\n",
    "    TPs, FPs, FNs = evaluate_dataset(dataset_path)\n",
    "    # Get metrics\n",
    "    precision = TPs / (TPs + FPs) if TPs + FPs > 0 else 0\n",
    "    recall = TPs / (TPs + FNs) if TPs + FNs > 0 else 0\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3e8e54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # Run tests on ARCS\n",
    "# precision, recall = test_pointpillars(ARCS_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8833a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Metrics for ARCS')\n",
    "# print('Precision: ' + str(precision))\n",
    "# print('Recall: ' + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7f534be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # Run tests on ARCS filtered\n",
    "# filter_precision, filter_recall = test_pointpillars(ARCS_FILTERED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "12d8e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Metrics for Filtered ARCS')\n",
    "# print('Precision: ' + str(filter_precision))\n",
    "# print('Recall: ' + str(filter_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fd5ed34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run tests on ARCS label filtered\n",
    "label_filter_precision, label_filter_recall = test_pointpillars(ARCS_LABEL_FILTERED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f4f82421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Label Filtered ARCS\n",
      "Precision: 0.6662468513853904\n",
      "Recall: 0.16884774976061284\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for Label Filtered ARCS')\n",
    "print('Precision: ' + str(label_filter_precision))\n",
    "print('Recall: ' + str(label_filter_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8945130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(last_file_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "792654ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "26922c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000317', '002189', '000316', '000155', '003442', '000353', '002182', '000153', '003247', '002609', '000355', '004018', '005238', '005159', '000314']\n"
     ]
    }
   ],
   "source": [
    "print(generated_problem_file_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
